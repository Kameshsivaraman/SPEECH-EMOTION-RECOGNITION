1.1	Project Introduction

Speech Emotion Recognition. SER is the process of trying to recognize human emotion and effective states from speech. Since we use tone and pitch to express emotion through voice, SER is possible, but it is tough because emotions are subjective and annotating audio is challenging. We’ll use the MFCC, Chroma, and Mel features and use the RAVDESS datasets to recognize emotion on. We’ll build an MLP Classifier for the model. As an example, speech produced in a state of fear, anger, or joy becomes loud and fast, with a higher and wider range in pitch, whereas emotions such as sadness or tiredness generate slow and low-pitched speech. SER consists of three components:
•	Speaker Identification
•	Speech Recognition
•	Speech Emotion Detection

Speech emotion detection can be built as a classification problem and can also be solved using several Machine Learning algorithms. Detection of human emotions through voice-pattern and speech-pattern analysis has many applications such as better assisting human-machine interactions. In particular, we are presenting a classification model of emotion elicited by speeches based on deep neural networks (CNNs), SVM, MLP Classification based on acoustic features such as Mel Frequency Cepstral Coefficient (MFCC). The model has been trained to classify eight different emotions (neutral, calm, happy, sad, angry, fearful, disgust, surprise). Our evaluation shows that the proposed approach yields accuracies of 70 – 80% using CNN, MLP Classifier and SVM Classifiers respectively, for 8 emotions using Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) dataset. We can find wide application of speech emotion recognition in Marketing, Health Care, Customer Satisfaction, Gaming Experiencing Improvement, Social Media Analysis, Stress Monitoring and much more. This project discusses in detail the various methods and experiment carried out as a part of implementing a speech emotion recognition system.
 
1.2	Scope of the Project

Speech emotion recognition (SER) plays a vital role in human machine interaction, biometrics security, etc. A large number of SER schemes have been anticipated over the last decade. However the performance of SER system is challenging due to the high complexity of the system, poor feature distinctiveness and noise. Speech Emotion Recognition Technology is now a multi-billion dollar industry that aims to use Artificial Intelligence to detect emotions from speech variations. Speech Recognition algorithms are trained on different speech patterns, languages, dialects and accents to adapt to human speech’s highly variable and context-specific nature. Speech based emotion analysis in real-time opens up many business opportunities by enabling an automated customer service agent to recognize a caller’s emotional state and adapt accordingly. Such information can also be helpful in analyzing and managing stress levels of human workers.
1.3	Objective of the Project

The primary objectives of Speech Emotion Recognition is to improve man-machine interface. The Aim of the project is to detect the emotions which are elicited by the speaker while speaking. Emotion recognition has become an essential task these days. The Speech which is in fear, anger, joy have higher a wider range pitch whereas have low range in pitch. The recognition of emotional speech aims to recognize the emotional condition of individual utterer by applying his/her voice automatically. It can also be used to monitor the psycho physiological state of a person in lie detectors. In reason time, speech emotion recognition also find its applications in medicine and forensics. At present, most of the work in this area utilizes extraction of discriminatory features for the purpose of classification of emotions into various categories. Users can either upload a pre-recorded audio file or record a new file and analyze it. This project has been developed using Python as their programming language. The goal of SER is to determine the emotional state of a speaker, such as happiness, sadness, anger or frustration, from their speech patterns, such as prosody, pitch and rhythm.
